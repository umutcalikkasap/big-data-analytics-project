{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Commerce Intent Prediction - Model Visualization\n",
    "\n",
    "Bu notebook, model sonuçlarını görselleştirir:\n",
    "- Confusion Matrix\n",
    "- ROC Curve\n",
    "- Feature Importance\n",
    "- Pandas vs Spark Karşılaştırması\n",
    "\n",
    "**Yazarlar:** Abdulkadir Külçe, Berkay Türk, Umut Çalıkkasap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Veri Yükleme ve Model Eğitimi\n",
    "\n",
    "Görselleştirme için sample veri kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri yükle (sample)\n",
    "SAMPLE_RATE = 0.05  # %5 sample\n",
    "DATA_PATH = \"../data/2019-Oct.csv\"\n",
    "\n",
    "print(f\"Loading data (sample rate: {SAMPLE_RATE*100}%)...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df.sample(frac=SAMPLE_RATE, random_state=42)\n",
    "print(f\"Loaded {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing (Leakage-Free)\n",
    "import gc\n",
    "\n",
    "print(\"Preprocessing...\")\n",
    "df['event_time'] = pd.to_datetime(df['event_time'])\n",
    "df['category_code'] = df['category_code'].fillna('unknown')\n",
    "df['brand'] = df['brand'].fillna('unknown')\n",
    "\n",
    "# Leakage Prevention\n",
    "purchases = df[df['event_type'] == 'purchase'][['user_session', 'event_time']]\n",
    "first_purchase = purchases.groupby('user_session')['event_time'].min().reset_index()\n",
    "first_purchase.columns = ['user_session', 'purchase_timestamp']\n",
    "df = df.merge(first_purchase, on='user_session', how='left')\n",
    "mask = (df['purchase_timestamp'].isna()) | (df['event_time'] <= df['purchase_timestamp'])\n",
    "df_clean = df[mask].copy()\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Clean data: {len(df_clean):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"Feature engineering...\")\n",
    "\n",
    "df_clean['is_view'] = (df_clean['event_type'] == 'view').astype(int)\n",
    "df_clean['is_cart'] = (df_clean['event_type'] == 'cart').astype(int)\n",
    "\n",
    "agg_funcs = {\n",
    "    'purchase_timestamp': lambda x: 1 if x.notna().any() else 0,\n",
    "    'is_view': 'sum',\n",
    "    'is_cart': 'sum',\n",
    "    'event_time': lambda x: (x.max() - x.min()).total_seconds(),\n",
    "    'price': ['mean', 'max'],\n",
    "    'product_id': 'nunique'\n",
    "}\n",
    "\n",
    "session_features = df_clean.groupby('user_session').agg(agg_funcs)\n",
    "session_features.columns = ['label', 'view_count', 'cart_count', 'session_duration',\n",
    "                             'avg_price', 'max_price', 'unique_items']\n",
    "session_features = session_features.fillna(0)\n",
    "\n",
    "print(f\"Sessions: {len(session_features):,}\")\n",
    "print(f\"Conversion rate: {session_features['label'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "print(\"Undersampling...\")\n",
    "\n",
    "minority = session_features[session_features['label'] == 1]\n",
    "majority = session_features[session_features['label'] == 0]\n",
    "\n",
    "majority_sampled = majority.sample(n=len(minority), random_state=42)\n",
    "balanced = pd.concat([minority, majority_sampled]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(f\"Balanced dataset: {len(balanced):,} sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "print(\"Training model...\")\n",
    "\n",
    "FEATURE_COLS = ['view_count', 'cart_count', 'session_duration', 'avg_price', 'max_price', 'unique_items']\n",
    "\n",
    "X = balanced[FEATURE_COLS]\n",
    "y = balanced['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=20, max_depth=5, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['No Purchase', 'Purchase'],\n",
    "            yticklabels=['No Purchase', 'Purchase'])\n",
    "\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "ax.set_title('Confusion Matrix - Intent Prediction Model', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Purchase', 'Purchase']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "ax.plot(fpr, tpr, color='#2ecc71', lw=2.5, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "ax.plot([0, 1], [0, 1], color='#e74c3c', lw=1.5, linestyle='--', label='Random Classifier')\n",
    "\n",
    "ax.fill_between(fpr, tpr, alpha=0.3, color='#2ecc71')\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curve - Purchase Intent Prediction', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': FEATURE_COLS,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(importance)))\n",
    "bars = ax.barh(importance['feature'], importance['importance'], color=colors)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, importance['importance']):\n",
    "    ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.3f}', va='center', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Importance', fontsize=12)\n",
    "ax.set_title('Feature Importance - Random Forest Model', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim([0, max(importance['importance']) * 1.15])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Importance Ranking:\")\n",
    "for i, row in importance.iloc[::-1].iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pandas vs Spark Karşılaştırması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Comparison Data (Progress Report'tan)\n",
    "benchmark_data = {\n",
    "    'Framework': ['Pandas', 'Spark'],\n",
    "    'Preprocessing (sec)': [780, 30],  # ~13 min vs ~0.5 min\n",
    "    'Training (sec)': [1.84, 485.49],\n",
    "    'AUC': [0.9276, 0.9276],\n",
    "    'F1-Score': [0.8366, 0.8366]\n",
    "}\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark_data)\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Comparison Chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Preprocessing Time\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "bars1 = axes[0].bar(['Pandas', 'Spark'], benchmark_df['Preprocessing (sec)'], color=colors)\n",
    "axes[0].set_ylabel('Time (seconds)', fontsize=12)\n",
    "axes[0].set_title('Preprocessing Time', fontsize=14, fontweight='bold')\n",
    "axes[0].bar_label(bars1, fmt='%.0f sec')\n",
    "\n",
    "# Training Time\n",
    "bars2 = axes[1].bar(['Pandas', 'Spark'], benchmark_df['Training (sec)'], color=colors)\n",
    "axes[1].set_ylabel('Time (seconds)', fontsize=12)\n",
    "axes[1].set_title('Training Time', fontsize=14, fontweight='bold')\n",
    "axes[1].bar_label(bars2, fmt='%.1f sec')\n",
    "\n",
    "plt.suptitle('Pandas vs Spark - Performance Comparison (~6GB Data)', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/benchmark_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small Data Paradox Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "data_sizes = [1, 5, 10, 50, 100, 500, 1000]  # GB\n",
    "pandas_viable = [1, 1, 0.8, 0, 0, 0, 0]  # Viability score\n",
    "spark_advantage = [0.2, 0.3, 0.5, 0.8, 0.9, 1.0, 1.0]  # Advantage score\n",
    "\n",
    "ax.fill_between(data_sizes, pandas_viable, alpha=0.3, color='#3498db', label='Pandas Viable Zone')\n",
    "ax.fill_between(data_sizes, spark_advantage, alpha=0.3, color='#e74c3c', label='Spark Advantage Zone')\n",
    "\n",
    "ax.axvline(x=6, color='green', linestyle='--', lw=2, label='Our Dataset (~6GB)')\n",
    "ax.axvline(x=16, color='orange', linestyle=':', lw=2, label='Typical RAM Limit (16GB)')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Data Size (GB)', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('\"Small Data Paradox\" - When to Use Which Framework?', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='center right')\n",
    "ax.set_xlim([1, 1000])\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/small_data_paradox.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Event Distribution (Funnel Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funnel Data (Progress Report'tan)\n",
    "funnel_data = {\n",
    "    'Event': ['View', 'Cart', 'Purchase'],\n",
    "    'Percentage': [96.1, 2.2, 1.7],\n",
    "    'Count': [40787794, 933346, 727624]  # Approximate\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie Chart\n",
    "colors_pie = ['#3498db', '#f39c12', '#2ecc71']\n",
    "explode = (0.02, 0.02, 0.05)\n",
    "axes[0].pie(funnel_data['Percentage'], labels=funnel_data['Event'], autopct='%1.1f%%',\n",
    "            colors=colors_pie, explode=explode, shadow=True, startangle=90)\n",
    "axes[0].set_title('Event Type Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Funnel Bar\n",
    "y_pos = range(len(funnel_data['Event']))\n",
    "bars = axes[1].barh(y_pos, funnel_data['Percentage'], color=colors_pie)\n",
    "axes[1].set_yticks(y_pos)\n",
    "axes[1].set_yticklabels(funnel_data['Event'])\n",
    "axes[1].set_xlabel('Percentage (%)', fontsize=12)\n",
    "axes[1].set_title('E-Commerce Funnel', fontsize=14, fontweight='bold')\n",
    "axes[1].bar_label(bars, fmt='%.1f%%')\n",
    "axes[1].set_xlim([0, 105])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/funnel_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary Dashboard\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Create grid\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Metrics Summary (Text)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.axis('off')\n",
    "metrics_text = \"\"\"\n",
    "MODEL METRICS\n",
    "─────────────\n",
    "AUC:      0.9276\n",
    "F1-Score: 0.8366\n",
    "Recall:   0.8385\n",
    "Accuracy: 0.8385\n",
    "\n",
    "DATASET\n",
    "─────────────\n",
    "Events:   42.4M\n",
    "Size:     ~6 GB\n",
    "Sessions: ~9M\n",
    "Conv.Rate: 6.8%\n",
    "\"\"\"\n",
    "ax1.text(0.1, 0.5, metrics_text, fontsize=12, fontfamily='monospace',\n",
    "         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "ax1.set_title('Summary', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Confusion Matrix\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "            xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('Actual')\n",
    "ax2.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. ROC Curve\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "ax3.plot(fpr, tpr, color='#2ecc71', lw=2, label=f'AUC = {auc(fpr, tpr):.4f}')\n",
    "ax3.plot([0, 1], [0, 1], 'r--', lw=1)\n",
    "ax3.fill_between(fpr, tpr, alpha=0.3, color='#2ecc71')\n",
    "ax3.set_xlabel('FPR')\n",
    "ax3.set_ylabel('TPR')\n",
    "ax3.legend(loc='lower right')\n",
    "ax3.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 4. Feature Importance\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "importance_sorted = importance.sort_values('importance', ascending=True)\n",
    "ax4.barh(importance_sorted['feature'], importance_sorted['importance'], color='steelblue')\n",
    "ax4.set_xlabel('Importance')\n",
    "ax4.set_title('Feature Importance', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 5. Time Comparison\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "ax5.bar(x - width/2, [780/60, 30/60], width, label='Preprocessing (min)', color='#3498db')\n",
    "ax5.bar(x + width/2, [1.84/60, 485.49/60], width, label='Training (min)', color='#e74c3c')\n",
    "ax5.set_xticks(x)\n",
    "ax5.set_xticklabels(['Pandas', 'Spark'])\n",
    "ax5.set_ylabel('Time (minutes)')\n",
    "ax5.legend()\n",
    "ax5.set_title('Framework Comparison', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 6. Funnel\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "ax6.pie([96.1, 2.2, 1.7], labels=['View', 'Cart', 'Purchase'], autopct='%1.1f%%',\n",
    "        colors=['#3498db', '#f39c12', '#2ecc71'], explode=(0.02, 0.02, 0.05))\n",
    "ax6.set_title('Event Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('E-Commerce Intent Prediction - Results Dashboard', fontsize=18, fontweight='bold', y=1.02)\n",
    "plt.savefig('../figures/dashboard.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ All visualizations saved to ../figures/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sonuç\n",
    "\n",
    "Bu notebook'ta:\n",
    "- **Confusion Matrix** ile model tahminlerini görselleştirdik\n",
    "- **ROC Curve** ile AUC=0.93 performansını gösterdik  \n",
    "- **Feature Importance** ile cart_count'un en önemli özellik olduğunu doğruladık\n",
    "- **Pandas vs Spark** karşılaştırması ile \"Small Data Paradox\"u gösterdik\n",
    "\n",
    "**Key Insight:** ~6GB veri için Pandas daha hızlı, ama Spark fault tolerance ve scalability sağlıyor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
